# save_to_csv.py - å­¦ä¹ ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶
import requests
from bs4 import BeautifulSoup
import pandas as pd  # è¿™æ˜¯å¤„ç†è¡¨æ ¼æ•°æ®çš„ä¸“ä¸šå·¥å…·ç®±

print("ğŸ’¾ å­¦ä¹ ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶")
print("=" * 50)

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}

response = requests.get('https://movie.douban.com/top250', headers=headers)

if response.status_code == 200:
    soup = BeautifulSoup(response.text, 'html.parser')
    all_movies = soup.find_all('div', class_='item')
    
    print(f"æ‰¾åˆ° {len(all_movies)} éƒ¨ç”µå½±ï¼Œå¼€å§‹æå–æ•°æ®...")
    
    # åˆ›å»ºä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰ç”µå½±æ•°æ®
    movies_data = []
    
    for i, movie in enumerate(all_movies, 1):
        # æå–ä¿¡æ¯
        title_span = movie.find('span', class_='title')
        title = title_span.text if title_span else "æœªçŸ¥æ ‡é¢˜"
        
        rating_span = movie.find('span', class_='rating_num')
        rating = rating_span.text if rating_span else "æ— è¯„åˆ†"
        
        # æå–è¯„ä»·äººæ•°ï¼ˆåªä¿ç•™æ•°å­—ï¼‰
        evaluation_count = "0"
        all_spans = movie.find_all('span')
        for span in all_spans:
            if 'äººè¯„ä»·' in span.text:
                # ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–çº¯æ•°å­—
                import re
                num_match = re.search(r'(\d+)', span.text)
                if num_match:
                    evaluation_count = num_match.group(1)
                break
        
        # æå–ç²¾åçŸ­è¯„
        quote_p = movie.find('p', class_='quote')
        if quote_p:
            quote_span = quote_p.find('span')
            short_comment = quote_span.text if quote_span else "æ— çŸ­è¯„"
        else:
            short_comment = "æ— çŸ­è¯„"
        
        # æŠŠæ•°æ®æ•´ç†æˆå­—å…¸æ ¼å¼
        movie_info = {
            'æ’å': i,
            'ç”µå½±æ ‡é¢˜': title,
            'è¯„åˆ†': float(rating),  # è½¬æ¢æˆæ•°å­—ï¼Œæ–¹ä¾¿åç»­åˆ†æ
            'è¯„ä»·äººæ•°': int(evaluation_count),  # è½¬æ¢æˆæ•°å­—
            'ç²¾åçŸ­è¯„': short_comment
        }
        
        movies_data.append(movie_info)
        
        # æ˜¾ç¤ºè¿›åº¦
        if i <= 3:
            print(f"âœ… å·²æå–: {title}")
    
    print(f"\nğŸ“Š æ•°æ®æå–å®Œæˆï¼å…± {len(movies_data)} éƒ¨ç”µå½±")
    
    # ä½¿ç”¨pandasåˆ›å»ºæ•°æ®æ¡†ï¼ˆç±»ä¼¼Excelè¡¨æ ¼ï¼‰
    print("\nğŸ› ï¸ æ­£åœ¨åˆ›å»ºæ•°æ®è¡¨æ ¼...")
    df = pd.DataFrame(movies_data)
    
    # æ˜¾ç¤ºè¡¨æ ¼é¢„è§ˆ
    print("\nğŸ“‹ æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰:")
    print(df.head())
    
    # ä¿å­˜ä¸ºCSVæ–‡ä»¶
    csv_filename = 'douban_top250_movies.csv'
    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ‰ æˆåŠŸä¿å­˜åˆ°æ–‡ä»¶: {csv_filename}")
    print("ğŸ’¡ ä½ å¯ä»¥ç”¨Excelæ‰“å¼€è¿™ä¸ªæ–‡ä»¶æŸ¥çœ‹æ•°æ®ï¼")
    
    # æ˜¾ç¤ºä¸€äº›åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“ˆ åŸºæœ¬ç»Ÿè®¡:")
    print(f"å¹³å‡è¯„åˆ†: {df['è¯„åˆ†'].mean():.2f}")
    print(f"æ€»è¯„ä»·äººæ•°: {df['è¯„ä»·äººæ•°'].sum():,} äºº")
    print(f"æœ€é«˜è¯„åˆ†: {df['è¯„åˆ†'].max()}")
    print(f"æœ€ä½è¯„åˆ†: {df['è¯„åˆ†'].min()}")
    
else:
    print("âŒ è·å–ç½‘é¡µå¤±è´¥")