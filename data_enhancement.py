# data_enhancement.py - æ•°æ®æ¸…æ´—ä¸å¢å¼º
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
from datetime import datetime

print("ğŸ”§ æ•°æ®æ¸…æ´—ä¸å¢å¼º")
print("=" * 50)

def crawl_douban_top250():
    """çˆ¬å–è±†ç“£TOP250æ•°æ®"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    response = requests.get('https://movie.douban.com/top250', headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    all_movies = soup.find_all('div', class_='item')
    
    movies_data = []
    
    for i, movie in enumerate(all_movies, 1):
        # æå–åŸºæœ¬ä¿¡æ¯
        title_span = movie.find('span', class_='title')
        title = title_span.text if title_span else "æœªçŸ¥æ ‡é¢˜"
        
        rating_span = movie.find('span', class_='rating_num')
        rating = rating_span.text if rating_span else "0"
        
        # æå–è¯„ä»·äººæ•°
        evaluation_count = "0"
        all_spans = movie.find_all('span')
        for span in all_spans:
            if 'äººè¯„ä»·' in span.text:
                num_match = re.search(r'(\d+)', span.text)
                if num_match:
                    evaluation_count = num_match.group(1)
                break
        
        # æå–çŸ­è¯„
        quote_p = movie.find('p', class_='quote')
        if quote_p:
            quote_span = quote_p.find('span')
            short_comment = quote_span.text if quote_span else "æ— çŸ­è¯„"
        else:
            short_comment = "æ— çŸ­è¯„"
        
        # æå–å¯¼æ¼”å’Œå¹´ä»½ä¿¡æ¯ï¼ˆæ–°å¢ï¼ï¼‰
        info_p = movie.find('p', class_='')
        if info_p:
            info_text = info_p.get_text()
            # ç®€å•çš„å¹´ä»½æå–ï¼ˆå®é™…é¡¹ç›®å¯ä»¥ç”¨æ›´å¤æ‚çš„æ–¹æ³•ï¼‰
            year_match = re.search(r'(\d{4})', info_text)
            year = year_match.group(1) if year_match else "æœªçŸ¥"
        else:
            year = "æœªçŸ¥"
        
        movie_info = {
            'æ’å': i,
            'ç”µå½±æ ‡é¢˜': title,
            'è¯„åˆ†': float(rating),
            'è¯„ä»·äººæ•°': int(evaluation_count),
            'ä¸Šæ˜ å¹´ä»½': year,
            'ç²¾åçŸ­è¯„': short_comment,
            'æ•°æ®æ¥æº': 'è±†ç“£TOP250',
            'é‡‡é›†æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        movies_data.append(movie_info)
    
    return pd.DataFrame(movies_data)

def enhance_data(df):
    """æ•°æ®å¢å¼ºå’Œæ¸…æ´—"""
    print("ğŸ”„ è¿›è¡Œæ•°æ®å¢å¼º...")
    
    # 1. æ•°æ®æ¸…æ´—ï¼šå¤„ç†å¯èƒ½çš„å¼‚å¸¸å€¼
    df = df[df['è¯„åˆ†'] >= 6.0]  # ç§»é™¤è¯„åˆ†å¼‚å¸¸ä½çš„ç”µå½±
    
    # 2. æ•°æ®å¢å¼ºï¼šåˆ›å»ºæ–°å­—æ®µ
    df['è¯„ä»·äººæ•°ç­‰çº§'] = pd.cut(df['è¯„ä»·äººæ•°'], 
                              bins=[0, 100000, 500000, 1000000, float('inf')],
                              labels=['å°ä¼—', 'çƒ­é—¨', 'å¾ˆç«', 'ç°è±¡çº§'])
    
    df['è¯„åˆ†ç­‰çº§'] = pd.cut(df['è¯„åˆ†'],
                          bins=[0, 8.5, 9.0, 9.5, 10],
                          labels=['è‰¯å¥½', 'ä¼˜ç§€', 'ç»å…¸', 'ç¥ä½œ'])
    
    # 3. è®¡ç®—è¡ç”ŸæŒ‡æ ‡
    df['çƒ­åº¦æŒ‡æ•°'] = (df['è¯„åˆ†'] * 0.7 + (df['è¯„ä»·äººæ•°'] / 1000000) * 0.3).round(2)
    
    print("âœ… æ•°æ®å¢å¼ºå®Œæˆï¼")
    return df

def analyze_data(df):
    """æ•°æ®åˆ†æ"""
    print("\nğŸ“Š æ•°æ®åˆ†æç»“æœ:")
    print("=" * 30)
    
    # åŸºæœ¬ç»Ÿè®¡
    print(f"â€¢ ç”µå½±æ•°é‡: {len(df)} éƒ¨")
    print(f"â€¢ è¯„åˆ†èŒƒå›´: {df['è¯„åˆ†'].min()} - {df['è¯„åˆ†'].max()}")
    print(f"â€¢ å¹³å‡è¯„åˆ†: {df['è¯„åˆ†'].mean():.2f}")
    print(f"â€¢ æ€»è¯„ä»·äººæ•°: {df['è¯„ä»·äººæ•°'].sum():,} äºº")
    
    # åˆ†å¸ƒåˆ†æ
    print(f"\nğŸ¯ è¯„åˆ†åˆ†å¸ƒ:")
    rating_stats = df['è¯„åˆ†ç­‰çº§'].value_counts()
    for level, count in rating_stats.items():
        print(f"  {level}: {count} éƒ¨")
    
    print(f"\nğŸ”¥ çƒ­åº¦åˆ†å¸ƒ:")
    popularity_stats = df['è¯„ä»·äººæ•°ç­‰çº§'].value_counts()
    for level, count in popularity_stats.items():
        print(f"  {level}: {count} éƒ¨")
    
    # æœ€ä½³æ¨è
    best_movie = df.loc[df['çƒ­åº¦æŒ‡æ•°'].idxmax()]
    print(f"\nğŸ† ç»¼åˆæ¨è: {best_movie['ç”µå½±æ ‡é¢˜']}")
    print(f"   è¯„åˆ†: {best_movie['è¯„åˆ†']} | çƒ­åº¦æŒ‡æ•°: {best_movie['çƒ­åº¦æŒ‡æ•°']}")

# ä¸»ç¨‹åº
if __name__ == "__main__":
    # 1. çˆ¬å–æ•°æ®
    print("ğŸ•¸ï¸ å¼€å§‹çˆ¬å–æ•°æ®...")
    df = crawl_douban_top250()
    
    # 2. æ•°æ®å¢å¼º
    df_enhanced = enhance_data(df)
    
    # 3. æ•°æ®åˆ†æ
    analyze_data(df_enhanced)
    
    # 4. ä¿å­˜å¢å¼ºåçš„æ•°æ®
    df_enhanced.to_csv('douban_top250_enhanced.csv', index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ å¢å¼ºæ•°æ®å·²ä¿å­˜: douban_top250_enhanced.csv")
    
    # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
    print("\nğŸ“‹ å¢å¼ºæ•°æ®é¢„è§ˆ:")
    print(df_enhanced[['æ’å', 'ç”µå½±æ ‡é¢˜', 'è¯„åˆ†', 'è¯„ä»·äººæ•°ç­‰çº§', 'è¯„åˆ†ç­‰çº§', 'çƒ­åº¦æŒ‡æ•°']].head(8))